Monte Carlo methods estimate state-value functions by averaging the returns observed after visits to a state.  The first-visit MC method averages returns following the first visit to a state, while the every-visit MC method averages returns following all visits.  These averages converge to the expected value as more returns are observed.  In control methods, action-value functions are approximated by averaging returns starting from state-action pairs.